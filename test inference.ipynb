{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d047585d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndividualTF(\n",
       "  (model): EncoderDecoder(\n",
       "    (encoder): Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (feed_forward): PointerwiseFeedforward(\n",
       "            (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sublayer): ModuleList(\n",
       "            (0): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (feed_forward): PointerwiseFeedforward(\n",
       "            (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sublayer): ModuleList(\n",
       "            (0): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (feed_forward): PointerwiseFeedforward(\n",
       "            (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sublayer): ModuleList(\n",
       "            (0): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (feed_forward): PointerwiseFeedforward(\n",
       "            (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sublayer): ModuleList(\n",
       "            (0): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (feed_forward): PointerwiseFeedforward(\n",
       "            (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sublayer): ModuleList(\n",
       "            (0): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (feed_forward): PointerwiseFeedforward(\n",
       "            (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sublayer): ModuleList(\n",
       "            (0): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): DecoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (src_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (feed_forward): PointerwiseFeedforward(\n",
       "            (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sublayer): ModuleList(\n",
       "            (0): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): DecoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (src_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (feed_forward): PointerwiseFeedforward(\n",
       "            (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sublayer): ModuleList(\n",
       "            (0): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): DecoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (src_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (feed_forward): PointerwiseFeedforward(\n",
       "            (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sublayer): ModuleList(\n",
       "            (0): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): DecoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (src_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (feed_forward): PointerwiseFeedforward(\n",
       "            (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sublayer): ModuleList(\n",
       "            (0): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): DecoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (src_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (feed_forward): PointerwiseFeedforward(\n",
       "            (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sublayer): ModuleList(\n",
       "            (0): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): DecoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (src_attn): MultiHeadAttention(\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (feed_forward): PointerwiseFeedforward(\n",
       "            (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sublayer): ModuleList(\n",
       "            (0): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): SublayerConnection(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (src_embed): Sequential(\n",
       "      (0): LinearEmbedding(\n",
       "        (lut): Linear(in_features=45, out_features=512, bias=True)\n",
       "      )\n",
       "      (1): PositionalEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (tgt_embed): Sequential(\n",
       "      (0): LinearEmbedding(\n",
       "        (lut): Linear(in_features=46, out_features=512, bias=True)\n",
       "      )\n",
       "      (1): PositionalEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (generator): Generator(\n",
       "      (proj): Linear(in_features=512, out_features=46, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from email.header import Header\n",
    "from operator import index\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import scipy.spatial\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "def create_dataset(\n",
    "    dataset_folder,\n",
    "    dataset_name,\n",
    "    val_size,\n",
    "    gt,\n",
    "    horizon,\n",
    "    delim=\"\\t\",\n",
    "    train=True,\n",
    "    eval=False,\n",
    "    verbose=False,\n",
    "):\n",
    "\n",
    "    if train == True:\n",
    "        datasets_list = os.listdir(os.path.join(dataset_folder, dataset_name, \"train\"))\n",
    "        full_dt_folder = os.path.join(dataset_folder, dataset_name, \"train\")\n",
    "    if train == False and eval == False:\n",
    "        datasets_list = os.listdir(os.path.join(dataset_folder, dataset_name, \"val\"))\n",
    "        full_dt_folder = os.path.join(dataset_folder, dataset_name, \"val\")\n",
    "    if train == False and eval == True:\n",
    "        datasets_list = os.listdir(os.path.join(dataset_folder, dataset_name, \"test\"))\n",
    "        full_dt_folder = os.path.join(dataset_folder, dataset_name, \"test\")\n",
    "\n",
    "    datasets_list = datasets_list\n",
    "\n",
    "    data = {}\n",
    "    data_src = []\n",
    "    data_trg = []\n",
    "    data_seq_start = []\n",
    "    data_frames = []\n",
    "    data_dt = []\n",
    "    data_peds = []\n",
    "\n",
    "    val_src = []\n",
    "    val_trg = []\n",
    "    val_seq_start = []\n",
    "    val_frames = []\n",
    "    val_dt = []\n",
    "    val_peds = []\n",
    "\n",
    "    if verbose:\n",
    "        print(\"start loading dataset\")\n",
    "        print(\"validation set size -> %i\" % (val_size))\n",
    "\n",
    "    for i_dt, dt in enumerate(datasets_list):\n",
    "        if verbose:\n",
    "            print(\"%03i / %03i - loading %s\" % (i_dt + 1, len(datasets_list), dt))\n",
    "        # if i_dt == 0 or i_dt == 1:\n",
    "        # data = pd.read_csv(os.path.join(full_dt_folder, dt), sep=\"\\t\", header=None)\n",
    "        # print(data.info())\n",
    "        # print(data.head())\n",
    "        raw_data = pd.read_csv(\n",
    "            os.path.join(full_dt_folder, dt),\n",
    "            delimiter=delim,\n",
    "            names=[\n",
    "                \"frame\",\n",
    "                \"ped\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"scale\",\n",
    "                \"head_x\",\n",
    "                \"head_y\",\n",
    "                \"l_ear_x\",\n",
    "                \"l_ear_y\",\n",
    "                \"l_elbow_x\",\n",
    "                \"l_elbow_y\",\n",
    "                \"l_eye_x\",\n",
    "                \"l_eye_y\",\n",
    "                \"l_foot_x\",\n",
    "                \"l_foot_y\",\n",
    "                \"l_hand_x\",\n",
    "                \"l_hand_y\",\n",
    "                \"l_hip_x\",\n",
    "                \"l_hip_y\",\n",
    "                \"l_knee_x\",\n",
    "                \"l_knee_y\",\n",
    "                \"l_shoulder_x\",\n",
    "                \"l_shoulder_y\",\n",
    "                \"neck_x\",\n",
    "                \"neck_y\",\n",
    "                \"r_ear_x\",\n",
    "                \"r_ear_y\",\n",
    "                \"r_elbow_x\",\n",
    "                \"r_elbow_y\",\n",
    "                \"r_eye_x\",\n",
    "                \"r_eye_y\",\n",
    "                \"r_foot_x\",\n",
    "                \"r_foot_y\",\n",
    "                \"r_hand_x\",\n",
    "                \"r_hand_y\",\n",
    "                \"r_hip_x\",\n",
    "                \"r_hip_y\",\n",
    "                \"r_knee_x\",\n",
    "                \"r_knee_y\",\n",
    "                \"r_shoulder_x\",\n",
    "                \"r_shoulder_y\",\n",
    "                \"R_1\",\n",
    "                \"R_2\",\n",
    "                \"R_3\",\n",
    "                \"T_1\",\n",
    "                \"T_2\",\n",
    "                \"T_3\",\n",
    "            ],\n",
    "            usecols=list(range(47)),\n",
    "            na_values=\"?\",\n",
    "        )\n",
    "\n",
    "        # print(raw_data.columns)\n",
    "        raw_data.sort_values(by=[\"frame\", \"ped\"], inplace=True)\n",
    "\n",
    "        inp, out, info = get_strided_data_clust(raw_data, gt, horizon, 1)\n",
    "\n",
    "        dt_frames = info[\"frames\"]\n",
    "        dt_seq_start = info[\"seq_start\"]\n",
    "        dt_dataset = np.array([i_dt]).repeat(inp.shape[0])\n",
    "        dt_peds = info[\"peds\"]\n",
    "\n",
    "        if val_size > 0 and inp.shape[0] > val_size * 2.5:\n",
    "            if verbose:\n",
    "                print(\"created validation from %s\" % (dt))\n",
    "            k = random.sample(np.arange(inp.shape[0]).tolist(), val_size)\n",
    "            val_src.append(inp[k, :, :])\n",
    "            val_trg.append(out[k, :, :])\n",
    "            val_seq_start.append(dt_seq_start[k, :, :])\n",
    "            val_frames.append(dt_frames[k, :])\n",
    "            val_dt.append(dt_dataset[k])\n",
    "            val_peds.append(dt_peds[k])\n",
    "            inp = np.delete(inp, k, 0)\n",
    "            out = np.delete(out, k, 0)\n",
    "            dt_frames = np.delete(dt_frames, k, 0)\n",
    "            dt_seq_start = np.delete(dt_seq_start, k, 0)\n",
    "            dt_dataset = np.delete(dt_dataset, k, 0)\n",
    "            dt_peds = np.delete(dt_peds, k, 0)\n",
    "        elif val_size > 0:\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"could not create validation from %s, size -> %i\"\n",
    "                    % (dt, inp.shape[0])\n",
    "                )\n",
    "\n",
    "        data_src.append(inp)\n",
    "        data_trg.append(out)\n",
    "        data_seq_start.append(dt_seq_start)\n",
    "        data_frames.append(dt_frames)\n",
    "        data_dt.append(dt_dataset)\n",
    "        data_peds.append(dt_peds)\n",
    "\n",
    "    data[\"src\"] = np.concatenate(data_src, 0)\n",
    "    data[\"trg\"] = np.concatenate(data_trg, 0)\n",
    "    data[\"seq_start\"] = np.concatenate(data_seq_start, 0)\n",
    "    data[\"frames\"] = np.concatenate(data_frames, 0)\n",
    "    data[\"dataset\"] = np.concatenate(data_dt, 0)\n",
    "    data[\"peds\"] = np.concatenate(data_peds, 0)\n",
    "    data[\"dataset_name\"] = datasets_list\n",
    "\n",
    "    mean = data[\"src\"].mean((0, 1))\n",
    "    std = data[\"src\"].std((0, 1))\n",
    "\n",
    "    if val_size > 0:\n",
    "        data_val = {}\n",
    "        data_val[\"src\"] = np.concatenate(val_src, 0)\n",
    "        data_val[\"trg\"] = np.concatenate(val_trg, 0)\n",
    "        data_val[\"seq_start\"] = np.concatenate(val_seq_start, 0)\n",
    "        data_val[\"frames\"] = np.concatenate(val_frames, 0)\n",
    "        data_val[\"dataset\"] = np.concatenate(val_dt, 0)\n",
    "        data_val[\"peds\"] = np.concatenate(val_peds, 0)\n",
    "\n",
    "        return IndividualTfDataset(data, \"train\", mean, std), IndividualTfDataset(\n",
    "            data_val, \"validation\", mean, std\n",
    "        )\n",
    "    # print(\"----------\")\n",
    "    # print(\"src\")\n",
    "    # print(data[\"src\"][0])\n",
    "    # print(\"-------\")\n",
    "    # print(\"trg\")\n",
    "    # print(data[\"trg\"][0])\n",
    "    return IndividualTfDataset(data, \"train\", mean, std), None\n",
    "\n",
    "    return IndividualTfDataset(data, \"train\", mean, std), IndividualTfDataset(\n",
    "        data_val, \"validation\", mean, std\n",
    "    )\n",
    "\n",
    "\n",
    "class IndividualTfDataset(Dataset):\n",
    "    def __init__(self, data, name, mean, std):\n",
    "        super(IndividualTfDataset, self).__init__()\n",
    "\n",
    "        self.data = data\n",
    "        self.name = name\n",
    "\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[\"src\"].shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            \"src\": torch.Tensor(self.data[\"src\"][index]),\n",
    "            \"trg\": torch.Tensor(self.data[\"trg\"][index]),\n",
    "            \"frames\": self.data[\"frames\"][index],\n",
    "            \"seq_start\": self.data[\"seq_start\"][index],\n",
    "            \"dataset\": self.data[\"dataset\"][index],\n",
    "            \"peds\": self.data[\"peds\"][index],\n",
    "        }\n",
    "\n",
    "\n",
    "def create_folders(baseFolder, datasetName):\n",
    "    try:\n",
    "        os.mkdir(baseFolder)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        os.mkdir(os.path.join(baseFolder, datasetName))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "def get_strided_data_clust(dt, gt_size, horizon, step):\n",
    "    inp_te = []\n",
    "    dtt = dt.astype(np.float32)\n",
    "    raw_data = dtt\n",
    "    # print(\"-----------\")\n",
    "    # print(\"In strided data --> raw data\")\n",
    "    # print(raw_data.shape)\n",
    "    # print(\"raw data 0\")\n",
    "    # print(raw_data.iloc[0])\n",
    "    ped = raw_data.ped.unique()\n",
    "    # print(ped)\n",
    "    frame = []\n",
    "    ped_ids = []\n",
    "    # print(dt)\n",
    "    # print(gt_size)\n",
    "    # print(horizon)\n",
    "    # print(step)\n",
    "    for p in ped:\n",
    "        # print(f\"p is  {p}\")\n",
    "        # print(\"u p in ped\")\n",
    "        # print(raw_data[raw_data.ped == p].shape)\n",
    "\n",
    "        # print(1 + (raw_data[raw_data.ped == p].shape[0] - gt_size - horizon) // step)\n",
    "\n",
    "        for i in range(\n",
    "            1 + (raw_data[raw_data.ped == p].shape[0] - gt_size - horizon) // step\n",
    "        ):\n",
    "\n",
    "            frame.append(\n",
    "                dt[dt.ped == p]\n",
    "                .iloc[i * step : i * step + gt_size + horizon, [0]]\n",
    "                .values.squeeze()\n",
    "            )\n",
    "            # print(\"%i,%i,%i\" % (i * 4, i * 4 + gt_size, i * 4 + gt_size + horizon))\n",
    "            inp_te.append(\n",
    "                raw_data[raw_data.ped == p]\n",
    "                .iloc[i * step : i * step + gt_size + horizon, 2:50]\n",
    "                .values\n",
    "            )\n",
    "            ped_ids.append(p)\n",
    "\n",
    "    frames = np.stack(frame)\n",
    "    inp_te_np = np.stack(inp_te)\n",
    "    ped_ids = np.stack(ped_ids)\n",
    "\n",
    "    # inp_relative_pos= inp_te_np-inp_te_np[:,:1,:]\n",
    "    inp_speed = np.concatenate(\n",
    "        (\n",
    "            np.zeros((inp_te_np.shape[0], 1, 2)),\n",
    "            inp_te_np[:, 1:, 0:2] - inp_te_np[:, :-1, 0:2],\n",
    "        ),\n",
    "        1,\n",
    "    )\n",
    "    # inp_accel = np.concatenate((np.zeros((inp_te_np.shape[0],1,2)),inp_speed[:,1:,0:2] - inp_speed[:, :-1, 0:2]),1)\n",
    "    # inp_std = inp_no_start.std(axis=(0, 1))\n",
    "    # inp_mean = inp_no_start.mean(axis=(0, 1))\n",
    "    # inp_norm= inp_no_start\n",
    "    # inp_norm = (inp_no_start - inp_mean) / inp_std\n",
    "\n",
    "    # vis=inp_te_np[:,1:,2:4]/np.linalg.norm(inp_te_np[:,1:,2:4],2,axis=2)[:,:,np.newaxis]\n",
    "    # inp_norm=np.concatenate((inp_norm,vis),2)\n",
    "    inp_norm = np.concatenate((inp_te_np, inp_speed), 2)\n",
    "    inp_mean = np.zeros(4)\n",
    "    inp_std = np.ones(4)\n",
    "\n",
    "    return (\n",
    "        inp_norm[:, :gt_size],\n",
    "        inp_norm[:, gt_size:],\n",
    "        {\n",
    "            \"mean\": inp_mean,\n",
    "            \"std\": inp_std,\n",
    "            \"seq_start\": inp_te_np[:, 0:1, :].copy(),\n",
    "            \"frames\": frames,\n",
    "            \"peds\": ped_ids,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "def distance_metrics(gt, preds):\n",
    "    errors = np.zeros(gt.shape[:-1])\n",
    "\n",
    "    for i in range(errors.shape[0]):\n",
    "        for j in range(errors.shape[1]):\n",
    "            errors[i, j] = scipy.spatial.distance.euclidean(gt[i, j], preds[i, j])\n",
    "    return errors.mean(), errors[:, -1].mean(), errors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformer.decoder import Decoder\n",
    "from transformer.multihead_attention import MultiHeadAttention\n",
    "from transformer.positional_encoding import PositionalEncoding\n",
    "from transformer.pointerwise_feedforward import PointerwiseFeedforward\n",
    "from transformer.encoder_decoder import EncoderDecoder\n",
    "from transformer.encoder import Encoder\n",
    "from transformer.encoder_layer import EncoderLayer\n",
    "from transformer.decoder_layer import DecoderLayer\n",
    "from transformer.batch import subsequent_mask\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "\n",
    "import copy\n",
    "import math\n",
    "\n",
    "class IndividualTF(nn.Module):\n",
    "    def __init__(self, enc_inp_size, dec_inp_size, dec_out_size, N=6,\n",
    "                   d_model=512, d_ff=2048, h=8, dropout=0.1,mean=[0,0],std=[0,0]):\n",
    "        super(IndividualTF, self).__init__()\n",
    "        \"Helper: Construct a model from hyperparameters.\"\n",
    "        c = copy.deepcopy\n",
    "        attn = MultiHeadAttention(h, d_model)\n",
    "        ff = PointerwiseFeedforward(d_model, d_ff, dropout)\n",
    "        position = PositionalEncoding(d_model, dropout)\n",
    "        self.mean=np.array(mean)\n",
    "        self.std=np.array(std)\n",
    "        self.model = EncoderDecoder(\n",
    "            Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "            Decoder(DecoderLayer(d_model, c(attn), c(attn),\n",
    "                                 c(ff), dropout), N),\n",
    "            nn.Sequential(LinearEmbedding(enc_inp_size,d_model), c(position)),\n",
    "            nn.Sequential(LinearEmbedding(dec_inp_size,d_model), c(position)),\n",
    "            Generator(d_model, dec_out_size))\n",
    "\n",
    "        # This was important from their code.\n",
    "        # Initialize parameters with Glorot / fan_avg.\n",
    "        for p in self.model.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, *input):\n",
    "        return self.model.generator(self.model(*input))\n",
    "\n",
    "class LinearEmbedding(nn.Module):\n",
    "    def __init__(self, inp_size,d_model):\n",
    "        super(LinearEmbedding, self).__init__()\n",
    "        # lut => lookup table\n",
    "        self.lut = nn.Linear(inp_size, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "\n",
    "    def __init__(self, d_model, out_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.proj(x)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = IndividualTF(\n",
    "        enc_inp_size=45,\n",
    "        dec_inp_size=46,\n",
    "        dec_out_size=46,\n",
    "        N=6,\n",
    "        d_model=512,\n",
    "        d_ff=2048,\n",
    "        h=8,\n",
    "        dropout=0.1,\n",
    "        mean=[0, 0],\n",
    "        std=[0, 0],\n",
    "    ).to(device)\n",
    "PATH = r\"C:\\Users\\alika\\Desktop\\research\\transformer-location-prediction\\models\\Individual\\fpl_train\\00408.pth\"\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "494fc6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start loading dataset\n",
      "validation set size -> 0\n",
      "001 / 002 - loading GOPR0321U20_imputed.txt\n",
      "002 / 002 - loading GOPR0324U20_imputed.txt\n"
     ]
    }
   ],
   "source": [
    "test_dataset, _ = create_dataset(\n",
    "        \"datasets\",\n",
    "        \"fpl\",\n",
    "        0,\n",
    "        8,\n",
    "        12,\n",
    "        delim=\"\\t\",\n",
    "        train=False,\n",
    "        eval=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=100, shuffle=False, num_workers=0\n",
    "    )\n",
    "mean = torch.cat(\n",
    "        (test_dataset[:][\"src\"][:, 1:, 2:47], test_dataset[:][\"trg\"][:, :, 2:47]), 1\n",
    "    ).mean((0, 1))\n",
    "    # std=train_dataset[:]['src'][:,1:,2:4].std((0,1))\n",
    "std = torch.cat(\n",
    "    (test_dataset[:][\"src\"][:, 1:, 2:47], test_dataset[:][\"trg\"][:, :, 2:47]), 1\n",
    ").std((0, 1))\n",
    "means = []\n",
    "stds = []\n",
    "for i in np.unique(test_dataset[:][\"dataset\"]):\n",
    "    ind = test_dataset[:][\"dataset\"] == i\n",
    "    means.append(\n",
    "        torch.cat(\n",
    "            (\n",
    "                test_dataset[:][\"src\"][ind, 1:, 2:47],\n",
    "                test_dataset[:][\"trg\"][ind, :, 2:47],\n",
    "            ),\n",
    "            1,\n",
    "        ).mean((0, 1))\n",
    "    )\n",
    "    stds.append(\n",
    "        torch.cat(\n",
    "            (\n",
    "                test_dataset[:][\"src\"][ind, 1:, 2:47],\n",
    "                test_dataset[:][\"trg\"][ind, :, 2:47],\n",
    "            ),\n",
    "            1,\n",
    "        ).std((0, 1))\n",
    "    )\n",
    "\n",
    "mean = torch.stack(means).mean(0)\n",
    "std = torch.stack(stds).mean(0)\n",
    "\n",
    "mean_list = mean.detach().tolist()\n",
    "for i, tens in enumerate(mean_list):\n",
    "    if tens == 0:\n",
    "        mean_list[i] = 0.00000001\n",
    "\n",
    "std_list = std.detach().tolist()\n",
    "for i, tens in enumerate(std_list):\n",
    "    if tens == 0:\n",
    "        std_list[i] = 0.00000001\n",
    "\n",
    "mean = torch.FloatTensor(mean_list)\n",
    "std = torch.FloatTensor(std_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c6e61b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp i trg\n",
      "tensor([ 0.8144,  0.9976,  1.0028,  0.5401,  0.1723, -0.4663, -0.9288, -1.2019],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5701, -1.3888, -1.2956, -1.3864, -1.5711, -1.6619, -1.3890, -1.2968,\n",
      "        -1.2080, -1.5709, -1.5696, -1.3877], device='cuda:0')\n",
      "-------\n",
      "dec inp\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')\n",
      "trg complete\n",
      "tensor([-1.5582, -6.7953, -1.5701, -6.3599, -3.2488,  5.0117,  4.6867, -6.7495,\n",
      "        -2.2241, -1.2661, -1.2760, -6.9972, -2.0054, -6.5960, -2.1782, -6.9817,\n",
      "        -1.7961, -6.9122, -1.8294,  0.0491,  1.0467, -7.0822, -1.4201, -6.3629,\n",
      "        -1.8793,  0.0566,  0.9013, -6.2828, -2.4123, -6.4094, -1.9951, -6.8383,\n",
      "        -1.9422, -6.3595, -2.2232, -6.7463, -1.7100,  2.7731, -1.0680, -1.5901,\n",
      "        -1.2694,  0.6703,  1.6357,  0.6951,  0.7787], device='cuda:0')\n",
      "out\n",
      "tensor([-1.7229e+00, -5.3969e+00, -4.0630e-03,  7.1856e-02, -2.0777e-02,\n",
      "        -6.8673e-03, -2.8257e-02,  2.5292e-02, -5.9083e-02, -1.6408e-02,\n",
      "        -3.2882e-02, -2.0407e-03,  5.1178e-02,  6.9845e-03, -2.5952e-02,\n",
      "         4.8018e-03, -7.8703e-03,  1.3988e-02, -1.0910e-02, -1.4598e-02,\n",
      "         8.8469e-03,  5.3390e-02,  3.0819e-02, -3.9470e-02,  3.1411e-02,\n",
      "        -4.8899e-02,  3.3079e-02, -2.4617e-02,  2.2616e-02, -3.0015e-02,\n",
      "         2.5761e-02,  2.3790e-02, -5.4920e-02, -4.5707e-02,  1.2736e-01,\n",
      "         7.4849e-02,  4.1418e-02,  1.1084e-02, -9.3123e-03,  3.3033e-02,\n",
      "        -3.3047e-02, -8.6492e-03,  1.1123e-02,  3.0846e-02, -1.0051e-02,\n",
      "         1.4590e-02], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "out 2 before\n",
      "tensor([-1.7229e+00, -5.3969e+00, -4.0630e-03,  7.1856e-02, -2.0777e-02,\n",
      "        -6.8673e-03, -2.8257e-02,  2.5292e-02, -5.9083e-02, -1.6408e-02,\n",
      "        -3.2882e-02, -2.0407e-03,  5.1178e-02,  6.9845e-03, -2.5952e-02,\n",
      "         4.8018e-03, -7.8703e-03,  1.3988e-02, -1.0910e-02, -1.4598e-02,\n",
      "         8.8469e-03,  5.3390e-02,  3.0819e-02, -3.9470e-02,  3.1411e-02,\n",
      "        -4.8899e-02,  3.3079e-02, -2.4617e-02,  2.2616e-02, -3.0015e-02,\n",
      "         2.5761e-02,  2.3790e-02, -5.4920e-02, -4.5707e-02,  1.2736e-01,\n",
      "         7.4849e-02,  4.1418e-02,  1.1084e-02, -9.3123e-03,  3.3033e-02,\n",
      "        -3.3047e-02, -8.6492e-03,  1.1123e-02,  3.0846e-02, -1.0051e-02,\n",
      "         1.4590e-02], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "out2 after\n",
      "tensor([-1.7229, -5.3969, -1.5701, -6.3599, -3.2488,  5.0117,  4.6867, -6.7495,\n",
      "        -2.2241, -1.2661, -1.2760, -6.9972, -2.0054, -6.5960, -2.1782, -6.9817,\n",
      "        -1.7961, -6.9122, -1.8294,  0.0491,  1.0467, -7.0822, -1.4201, -6.3629,\n",
      "        -1.8793,  0.0566,  0.9013, -6.2828, -2.4123, -6.4094, -1.9951, -6.8383,\n",
      "        -1.9422, -6.3595, -2.2232, -6.7463, -1.7100,  2.7731, -1.0680, -1.5901,\n",
      "        -1.2694,  0.6703,  1.6357,  0.6951,  0.7787,  0.0146], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 4.00 GiB total capacity; 2.67 GiB already allocated; 0 bytes free; 2.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11932/3161475014.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         )\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_inp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_att\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg_att\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;31m#print(\"inp complete\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer-trajectory\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11932/440887744.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mLinearEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer-trajectory\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\research\\transformer-location-prediction\\transformer\\encoder_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mTake\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0msrc\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \"\"\"\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\research\\transformer-location-prediction\\transformer\\encoder_decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, memory, src_mask, tgt, tgt_mask)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtgt_embed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer-trajectory\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\research\\transformer-location-prediction\\transformer\\decoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, memory, src_mask, tgt_mask)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer-trajectory\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\research\\transformer-location-prediction\\transformer\\decoder_layer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, memory, src_mask, tgt_mask)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc_attn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer-trajectory\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\research\\transformer-location-prediction\\transformer\\sublayer_connection.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, sublayer)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mApply\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0mconnection\u001b[0m \u001b[0mto\u001b[0m \u001b[0many\u001b[0m \u001b[0msublayer\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \"\"\"\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msublayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\research\\transformer-location-prediction\\transformer\\decoder_layer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc_attn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer-trajectory\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\research\\transformer-location-prediction\\transformer\\multihead_attention.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, mask)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mnbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# 1) Do all the linear projections in batch from d_model => h x d_k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for l, x in\n\u001b[0m\u001b[0;32m     33\u001b[0m                              zip(self.linears, (query, key, value))]\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# 2) Apply attention on all the projected vectors in batch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\research\\transformer-location-prediction\\transformer\\multihead_attention.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mnbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# 1) Do all the linear projections in batch from d_model => h x d_k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for l, x in\n\u001b[0m\u001b[0;32m     33\u001b[0m                              zip(self.linears, (query, key, value))]\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# 2) Apply attention on all the projected vectors in batch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer-trajectory\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer-trajectory\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer-trajectory\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 4.00 GiB total capacity; 2.67 GiB already allocated; 0 bytes free; 2.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "gt = []\n",
    "pr = []\n",
    "inp_ = []\n",
    "peds = []\n",
    "frames = []\n",
    "dt = []\n",
    "\n",
    "for id_b, batch in enumerate(test_dl):\n",
    "    \n",
    "    inp_.append(batch[\"src\"])\n",
    "    gt.append(batch[\"trg\"][:, :, 0:2])\n",
    "    frames.append(batch[\"frames\"])\n",
    "    peds.append(batch[\"peds\"])\n",
    "    dt.append(batch[\"dataset\"])\n",
    "\n",
    "    inp = (\n",
    "        batch[\"src\"][:, :, 2:47].to(device) - mean.to(device)\n",
    "    ) / std.to(device)\n",
    "    trg = (\n",
    "        batch[\"trg\"][:, :, 2:47].to(device) - mean.to(device)\n",
    "    ) / std.to(device)\n",
    "    print(\"inp i trg\")\n",
    "    print(inp[0, :, 2])\n",
    "    print(trg[0, :, 2])\n",
    "    src_att = torch.ones((inp.shape[0], 1, inp.shape[1])).to(device)\n",
    "\n",
    "    start_of_seq = (\n",
    "        torch.Tensor(\n",
    "            [\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                1,\n",
    "            ]\n",
    "        )\n",
    "        .unsqueeze(0)\n",
    "        .unsqueeze(1)\n",
    "        .repeat(inp.shape[0], 1, 1)\n",
    "        .to(device)\n",
    "    )\n",
    "    dec_inp = start_of_seq\n",
    "    \n",
    "    for i in range(12):\n",
    "        trg_att = (\n",
    "            subsequent_mask(dec_inp.shape[1])\n",
    "            .repeat(dec_inp.shape[0], 1, 1)\n",
    "            .to(device)\n",
    "        )\n",
    "        out = model(inp, dec_inp, src_att, trg_att)\n",
    "        print(\"-------\")\n",
    "        #print(\"inp complete\")\n",
    "        #print(inp[:, i, :][0])\n",
    "        print(\"dec inp\")\n",
    "        print(dec_inp[:, i, :][0])\n",
    "        print(\"trg complete\")\n",
    "        print(trg[:, i, :][0])\n",
    "        print(\"out\")\n",
    "        print(out[:, -1, :][0])\n",
    "        out_2 = out\n",
    "        print(\"out 2 before\")\n",
    "        print(out_2[:, -1, :][0])\n",
    "        \n",
    "        out_2[:, -1, 2:45] = trg[:, i, 2:]\n",
    "        #print(out_2[:, -1, 2:])\n",
    "        print(\"out2 after\")\n",
    "        print(out_2[:, -1, :][0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        dec_inp = torch.cat((dec_inp, out_2), 1)\n",
    "        \n",
    "\n",
    "    preds_tr_b = (\n",
    "        dec_inp[:, 1:, 0:2] * std[:2].to(device) + mean[:2].to(device)\n",
    "    ).detach().cpu().numpy().cumsum(1) + batch[\"src\"][:, -1:, 0:2].detach().cpu().numpy()\n",
    "    pr.append(preds_tr_b)\n",
    "    \n",
    "\n",
    "peds = np.concatenate(peds, 0)\n",
    "frames = np.concatenate(frames, 0)\n",
    "dt = np.concatenate(dt, 0)\n",
    "gt = np.concatenate(gt, 0)\n",
    "dt_names = test_dataset.data[\"dataset_name\"]\n",
    "pr = np.concatenate(pr, 0)\n",
    "# print(type(gt))\n",
    "# print(\"gt type gore, dole pr\")\n",
    "# print(type(pr))\n",
    "#print(pr.shape)\n",
    "#print(pr)\n",
    "#print(gt)\n",
    "mad, fad, errs = distance_metrics(gt, pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0777909c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3144.950979232788"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "48f85997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5733.886047363281"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875bc009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
